MHC-II TMH epitopes
========================================================
author: RichÃ¨l J.C. Bilderbeek
date:
autosize: true

```
https://github.com/richelbilderbeek/
mimy_presentation_20200818
```

![](CC-BY-NC-SA.png)

Epitope presentation
========================================================

![](fimmu-08-01118-g005_smaller.jpg)

***

Bianchi, Textor, van den Bogaart. 2017. "Transmembrane Helices are an overlooked source of Major Histocompatibility Complex Class I epitopes." Frontiers in Immunology

TMHs are presentated more often
========================================================

![](fimmu-08-01118-g001a.png)

***

![](frans_and_geert_and_johannes.jpg)

My job
========================================================

> "Could you do this for MHC-II as well?"

***

![](frans_and_geert.jpg)

My job in a nutshell
========================================================

```
SWINGTRANSMITWILLINGFASCINATEARISERISKGRATE
0000000000000000001111111111111111111110000
......xxxxxxxxxxxxxxxxxxxxxxxxx
 A-----------A
            B-----------B
                     C-----------C
```

n_binders|n_binder_tmh|n_spots  |n_spots_tmh
---------|------------|---------|------------
3        |2           |31       |25

Goal
========================================================

 * Reproducible research
 * Modern [1] and free prediction software
 * Usable by others
 * High quality work

[1] Spoiler: I will regret this

Differences with earlier study
========================================================

 * Added 21 MHC-II haplotypes
 * Definition of a binder
 * Modern and free prediction software

Modern and free prediction software
========================================================

Goal                    |Classical study|Year|My study  |Year
------------------------|---------------|----|----------|-----
TMH prediction          |TMHMM [1]      |2001|PureseqTM |2019
IC50 prediction (MHC-I) |Textor's       |2009|MHCnuggets|2020
IC50 prediction (MHC-II)|.              |.   |MHCnuggets|2020

 * [1] from a server (can now also use https://github.com/richelbilderbeek/tmhmm)

Problem
========================================================

 * TMH prediction by PureseqTM has a CLI
 * IC50 prediction by MHCnuggets is written in Python
 * No time to learn Python, stick with R

Solution
========================================================

I wrote two R packages:

Goal           |Tool       |R package
---------------|-----------|-------------
TMH prediction |PureseqTM  |`pureseqtmr`
IC50 prediction|MHCnuggets |`mhcnuggetsr`

 * `pureseqtmr` is already on CRAN

Demo
========================================================

```{r cache=TRUE}
pureseqtmr::predict_topology_from_sequence(
  "IDEALLYFANTASTICALLYSIMPLIFYTHINKS"
)
```

Demo
========================================================

```{r cache=TRUE}
mhcnuggetsr::predict_ic50(
  mhcnuggetsr::create_mhcnuggets_options(
    mhc = "HLA-DPB103:01"
  ),
  peptides = "FANTASTICALLY"
)$ic50
```

Definition of a binder in text
========================================================

> "IC50 values for all 9-mers from the human proteome were predicted. The 2% peptides with the lowest IC50 values were defined as binders"

Peptide [*] |IC50 1|IC50 2|IC50 3
------------|------|------|------
AAAAAAAAARG |1     |1     |100
EEEEEEEEEKS |2k    |2k    |200k

Definition of a binder in code
========================================================

```
x <- read.fasta("UP000005640_9606.fasta")

for(i in seq_along(x)){
	# ...
	xb <- binders(
	  x[[i]], mhc,
	  quantile.threshold = .02
	)
	# ...
}
```

Definition of a binder we use
========================================================

A binder has an IC50 in the lowest 2% of all IC50s.

***

```{r echo=FALSE,fig.height=6,cache=TRUE}
ggplot2::ggplot(
  mhcnpreds::get_lut(9, "HLA-DPB103:01"),
  ggplot2::aes(x = q, y = ic50)
) + ggplot2::geom_point() +
  ggplot2::geom_vline(
    xintercept = 0.02,
    color = "blue"
  ) +
  ggplot2::geom_hline(
    yintercept = mhcnpreds::get_ic50_threshold(
      peptide_length = 9,
      mhc_haplotype = "HLA-DPB103:01",
      percentile = 0.02
    ),
    color = "red"
  )
```

Solution
========================================================

I wrote a package with lookup tables, `mhcnpreds`:

```{r cache=TRUE}
mhcnpreds::get_ic50_threshold(
  peptide_length = 9,
  mhc_haplotype = "HLA-DPB103:01",
  percentile = 0.02
)
```

The bbbq package
========================================================

Combines all these:

 * TMH prediction by `pureseqtmr`
 * IC50 prediction: `mucnuggetsr`
 * Epitope prediction: `mhcnpreds`

Demo
========================================================

```{r cache=TRUE}
t <- bbbq::predict_counts(
  peptide = paste0(
    "SWINGTRANSMITWILLINGFASCINATEARISE",
    "RISKGRATEENTERTAININGSHARPERPANDER"
  ),
  haplotype = "HLA-DPB103:01",
  peptide_length = 13,
  percentile = 0.02
)
```

Just what I needed :-)
========================================================

```{r}
knitr::kable(t)
```

 * Takes only 55 seconds on average!

Results (83 / 75004 proteins)
========================================================

![](fig_f_tmh_mhc1_grid_20.png)

***

![](fig_f_tmh_mhc2_grid_25.png)

Results (1470 / 75004 proteins)
========================================================

![](fig_f_tmh_mhc1_grid_partial_20.png)

***

![](fig_f_tmh_mhc2_grid_partial_20.png)

So, you're done?
========================================================

Scaling up may be harder than you think.

Total runtime
========================================================

 * Human proteome has 75k proteins
 * There are 34 haplotypes
 * One protein takes 55 seconds on average
 * Total: 1623 days

Solution: split up into jobs

ETA: +16 days if 100 jobs running

Total number of jobs
========================================================

 * Need 2.6 millions jobs
 * Peregrine allows for 1000 jobs max

Solution: write code to always fill up to 950 jobs in the queue.

Number of files
========================================================

 * 2.6 million files needed
 * Cluster maximum: 1.1 million files

Doable

Working with files
========================================================

```
ls *.csv
```

 * bash can have 2 million characters for arguments
 * filename has 23 characters on average
 * Cannot use basic command after 87k files

Solution: use workarounds for basic file operations

File sizes
========================================================

 * One job = 1 count file (8 kb) + 1 log file (51 kb)
 * Total disk usage: 20.4 Gb (counts only)
 * Total disk usage: 150.8 Gb (all files)
 * Cluster limit: 250 Gb

Doable

But how fast is it really?
========================================================

 * First job: 2020-08-13T14:07:17
 * Approx 4 days ago
 * 2240 proteins (of 75k) done
 * Approx 500 proteins per day
 * ETA: +150 days

Conclusion
========================================================

 * Wrote at least 5 packages that can be used by anyone
 * 55 secs per job -> 150 days of running
 * Can use partial results
 * Need to use older methods
